{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=right src=\"images/inmas.png\" width=130x />\n",
    "\n",
    "# Notebook 03b - Multiple Linear Regression - Supplement\n",
    "\n",
    "Material covered in this notebook:\n",
    "\n",
    "This notebook follows along the notes [here](Notes/3_MultipleLinearRegression.pdf)\n",
    "\n",
    "\n",
    "### Prerequisite\n",
    "Notebook 03a\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "981Xg40kn6xU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-KVZCcoyxl-"
   },
   "source": [
    "# Feature Selection for Regression\n",
    "\n",
    "We introduced multiple regression, which involved estimating the coefficients of a linear relationship between a dependent/response variable $Y$ and independent/predictor/feature variables $X_1,\\dots,X_k$:\n",
    "\n",
    "$$Y=\\beta_0 + \\beta_1X_1 +\\cdots + \\beta_kX_k$$\n",
    "\n",
    "How do we know that we have put the right covariates into the model. How can we tell if our model is \"good\" or even \"best\"?\n",
    "\n",
    "Let's revisit the course evaluation dataset and see if we can do better than our simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1690399925558,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "4A5swe-4rBGi",
    "outputId": "2f9154b5-6c1a-4c18-ef86-8b2d4484d7a9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/akmand/datasets/master/openintro/evals.csv\")\n",
    "display(data)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1690399720218,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "zXR1d39b7C4F",
    "outputId": "7cf62dee-b65a-4704-bf3c-3b119fea7749"
   },
   "outputs": [],
   "source": [
    "linear_model_formulation = smf.ols(\"score ~ bty_avg\", data = data)\n",
    "\n",
    "lm_results = linear_model_formulation.fit()\n",
    "lm_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1690399739351,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "x1lmGlBK7Fax",
    "outputId": "805aad98-d09c-4fa5-ac06-4b3709ed3f25"
   },
   "outputs": [],
   "source": [
    "beta_ests = np.flip(np.array(lm_results.params))\n",
    "x_vals = np.linspace(0,11,1000)\n",
    "y_vals = [np.polyval(beta_ests, i) for i in x_vals]\n",
    "\n",
    "plt.plot(x_vals, y_vals, color= 'blue', linewidth=3, zorder = 2)\n",
    "plt.scatter(data.bty_avg, data.score, color = 'black', zorder = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1690399746639,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "uF7MHK467Hqa",
    "outputId": "aa3cfc60-72e9-4c02-f058-0605364d1d26"
   },
   "outputs": [],
   "source": [
    "lm_summary = lm_results.summary()\n",
    "print(lm_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1690400833532,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "6gs-FfxD7Ku0",
    "outputId": "901c0ef4-7285-4373-daec-b68e21ceba06"
   },
   "outputs": [],
   "source": [
    "#R^2 adjusted for the linear model\n",
    "lm_results.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1690400842890,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "vscoTIwPvc8T",
    "outputId": "24e3367d-ea50-48e7-b59c-124af4b915c0"
   },
   "outputs": [],
   "source": [
    "lm_results.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1690400844790,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "bbXOh08qvdfs",
    "outputId": "99007c36-4b42-429f-cabf-825e48fa271c"
   },
   "outputs": [],
   "source": [
    "lm_results.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is8swwVvraOE"
   },
   "source": [
    "We are only explaining about 3% of the variation in course evaluation scores. What else can we add to the model to help us without the model getting too unwieldy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXE5uhHh3o0d"
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "Clearly a balance must be struck between model's complexity and  its capacity to effectively predict new data. The methods by which we strike this balance in practice fall under the category of **model selection**. The model selection task is typically cast as an application of **Occam's razor**, which may be summarized as:\n",
    "\n",
    "   \"Entities should not be multiplied beyond necessity.\"\n",
    "    \n",
    "I.e., in the presence of (equally likely) competing explanations for a phenomenon, the simplest should be preferred.\n",
    "\n",
    "In parametric settings, this is typically carried out by computing, for each model under consideration, an expression of the form\n",
    "\n",
    "$$\\text{log-likelihood} - \\text{complexity penalty}$$\n",
    "\n",
    "Commonly used model selection criteria which fall under this paradigm include the **Akaike information criterion** (AIC) and **Bayesian information criterion** (BIC) which penalize the log-likelihood penalty respectively with\n",
    "\n",
    "$$p_{\\text{AIC}}=k\\\\\n",
    "p_{\\text{BIC}} = \\frac{k}{2}\\log n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhDPjgj93uW4"
   },
   "source": [
    "## Forward Selection of Features\n",
    "\n",
    "Forward selection involves the following procedure:\n",
    "\n",
    "   1. Start with an empty regression model (i.e., just an intercept, if appropriate).\n",
    "   2. For each feature not yet included, fit the model associated by including only that feature among.\n",
    "   3. Note either the significance of the new feature (in the `.summary()` call) or a desired model selection criterion.\n",
    "   4. If there is at least one feature which is significant or improves the criterion, keep the feature which is most significant or most improves the criterion and return to step 2.\n",
    "   5. If no additional feature is significant or improves the criterion, return the model without any new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg1cXytD3xgO"
   },
   "source": [
    "We will first use the $\\text{adjusted-}R^2$ as our criterion since there's so few data. The adjusted R^2 accounts for the fact that we add complexity every time we add a new covariate. The regular R^2 will always increase when we add a new covariate. This is not necessarily true of the adjusted version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frg9m3YzsAz7"
   },
   "source": [
    "To simplify we will only consider a subset of the covariates.\n",
    "\n",
    "- rank\n",
    "- ethnicity\n",
    "- gender\n",
    "- age\n",
    "- cls_perc_eval\n",
    "- bty_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1690400068069,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "1Utbd1fY3xEH",
    "outputId": "00a134d6-09ff-4ac8-b333-6d12710c24da"
   },
   "outputs": [],
   "source": [
    "results_rank_only = smf.ols(\"score ~ rank\", data = data).fit()\n",
    "results_ethnicity_only = smf.ols(\"score ~ ethnicity\", data = data).fit()\n",
    "results_gender_only = smf.ols(\"score ~ gender\", data = data).fit()\n",
    "results_age_only = smf.ols(\"score ~ age\", data = data).fit()\n",
    "results_cls_perc_eval_only = smf.ols(\"score ~ cls_perc_eval\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for rank only is \"+ str(results_rank_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for ethnicity only is \"+ str(results_ethnicity_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for gender only is \"+ str(results_gender_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for age only is \"+ str(results_age_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for cls_perc_eval only is \"+ str(results_cls_perc_eval_only.rsquared_adj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO_oEClispJn"
   },
   "source": [
    "It looks like using bty_score is the best first covariate. Now what can we add to it to improve the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1690400179748,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "jQjRc1iT3oOK",
    "outputId": "c272ebb5-ba2a-4042-c968-a915a1d8f8e2"
   },
   "outputs": [],
   "source": [
    "results_bty_rank_only = smf.ols(\"score ~ rank + bty_avg\", data = data).fit()\n",
    "results_bty_ethnicity_only = smf.ols(\"score ~ ethnicity + bty_avg\", data = data).fit()\n",
    "results_bty_gender_only = smf.ols(\"score ~ gender + bty_avg\", data = data).fit()\n",
    "results_bty_age_only = smf.ols(\"score ~ age + bty_avg\", data = data).fit()\n",
    "results_bty_cls_perc_eval_only = smf.ols(\"score ~ cls_perc_eval + bty_avg\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for bty_rank only is \"+ str(results_bty_rank_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_ethnicity only is \"+ str(results_bty_ethnicity_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_gender only is \"+ str(results_bty_gender_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_age only is \"+ str(results_bty_age_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_perc_eval only is \"+ str(results_bty_cls_perc_eval_only.rsquared_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faPmE7ivs94r"
   },
   "source": [
    "bty_avg and cls_perc_eval work best together. Now what do we add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1690400268250,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "sVXsrs8dtC2C",
    "outputId": "e5d42bfb-8678-4d2b-d47e-2a8eb7a366d4"
   },
   "outputs": [],
   "source": [
    "results_bty_cls_rank_only = smf.ols(\"score ~ rank + bty_avg + cls_perc_eval\", data = data).fit()\n",
    "results_bty_cls_ethnicity_only = smf.ols(\"score ~ ethnicity + bty_avg  + cls_perc_eval\", data = data).fit()\n",
    "results_bty_cls_gender_only = smf.ols(\"score ~ gender + bty_avg  + cls_perc_eval\", data = data).fit()\n",
    "results_bty_cls_age_only = smf.ols(\"score ~ age + bty_avg  + cls_perc_eval\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for bty_cls_rank only is \"+ str(results_bty_cls_rank_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_ethnicity only is \"+ str(results_bty_cls_ethnicity_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_gender only is \"+ str(results_bty_cls_gender_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_age only is \"+ str(results_bty_cls_age_only.rsquared_adj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7stVQQLmtT9u"
   },
   "source": [
    "Adding gender helps. Let's keep going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690400331190,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "9Pd6jnxFtXSM",
    "outputId": "8e442f2c-7cde-44bd-9a7d-62363074fe71"
   },
   "outputs": [],
   "source": [
    "results_bty_cls_gender_rank_only = smf.ols(\"score ~ rank + bty_avg + cls_perc_eval + gender\", data = data).fit()\n",
    "results_bty_cls_gender_ethnicity_only = smf.ols(\"score ~ ethnicity + bty_avg  + cls_perc_eval + gender\", data = data).fit()\n",
    "results_bty_cls_gender_age_only = smf.ols(\"score ~ age + bty_avg  + cls_perc_eval + gender\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for bty_cls_gender_rank only is \"+ str(results_bty_cls_gender_rank_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_gender_ethnicity only is \"+ str(results_bty_cls_gender_ethnicity_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_gender_age only is \"+ str(results_bty_cls_gender_age_only.rsquared_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdEcZr4etjo7"
   },
   "source": [
    "Rank helps but we start to see diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690400387242,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "mRZhQW6Htmin",
    "outputId": "34038ba5-b3c9-4d87-86d5-07e5d697a367"
   },
   "outputs": [],
   "source": [
    "results_bty_cls_gender_rank_ethnicity_only = smf.ols(\"score ~ ethnicity + bty_avg  + cls_perc_eval + gender + rank\", data = data).fit()\n",
    "results_bty_cls_gender_rank_age_only = smf.ols(\"score ~ age + bty_avg  + cls_perc_eval + gender + rank\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for bty_cls_gender_rank_ethnicity only is \"+ str(results_bty_cls_gender_rank_ethnicity_only.rsquared_adj))\n",
    "print(\"Adj Rsquared for bty_cls_gender_rank_age only is \"+ str(results_bty_cls_gender_rank_age_only.rsquared_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WtYDNQgtwjr"
   },
   "source": [
    "Age helps. Should we add the last variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690400430182,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "txF1gtq0tzcJ",
    "outputId": "8a92beea-a217-4b66-c79a-9354a9b6ef23"
   },
   "outputs": [],
   "source": [
    "results_bty_cls_gender_rank_age_ethnicity_only = smf.ols(\"score ~ ethnicity + bty_avg  + cls_perc_eval + gender + rank + age\", data = data).fit()\n",
    "\n",
    "\n",
    "print(\"Adj Rsquared for bty_cls_gender_rank_age_ethnicity only is \"+ str(results_bty_cls_gender_rank_age_ethnicity_only.rsquared_adj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ddj1TBdet6oX"
   },
   "source": [
    "This marginally helps. So the \"full\" model is not overkill based on this metric. Recall that this isn't really a full model because we only considered a subset of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp17EAEFqFUY"
   },
   "source": [
    "## Backward Selection of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dR9vFAhqJG-"
   },
   "source": [
    "If forward selection involves incrementally adding features to our model, then it naturally stands to reason that **backward selection** involves incrementally *removing* features. The procedure is as follows:\n",
    "\n",
    " 1. Start with a full regression model.\n",
    " 2. For each feature included in the model, fit the model which omits that feature.\n",
    " 3. Note the model selection criterion in question.\n",
    " 4. If there is at least one feature which, upon omission, improves the model selection criterion, omit the feature which results in the largest improvement, and return to step 2.\n",
    " 5. Else, if omitting any feature does not improve the model selection criterion, return the current model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yl0jROHuJGy"
   },
   "source": [
    "In this case we are going to see if the variables are statistically significant in the presence of the other variables (at the 0.05 level).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1690400629707,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "578SYRqoucbC",
    "outputId": "cb22beee-16a1-48c4-ef73-6aac2d49aba3"
   },
   "outputs": [],
   "source": [
    "full_mod = smf.ols(\"score ~ ethnicity + bty_avg  + cls_perc_eval + gender + rank + age\", data = data).fit()\n",
    "full_summary = full_mod.summary()\n",
    "print(full_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIXrz0adutPW"
   },
   "source": [
    "The ethnicity binary categorical variable is not significant. We can remove it from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690400678546,
     "user": {
      "displayName": "Sara Stoudt",
      "userId": "03438098334645453392"
     },
     "user_tz": 240
    },
    "id": "gdAbFzWOuydB",
    "outputId": "c83b26c5-6362-427f-a866-6d995578b070"
   },
   "outputs": [],
   "source": [
    "smaller_mod = smf.ols(\"score ~ bty_avg  + cls_perc_eval + gender + rank + age\", data = data).fit()\n",
    "smaller_summary = smaller_mod.summary()\n",
    "print(smaller_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rQHWXS9u31t"
   },
   "source": [
    "Everything else is statistically significant. We can stop with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKwe_AzpqJrk"
   },
   "source": [
    "## Your turn: Feature Selection for Iris Data\n",
    "\n",
    "Perform forward feature selection on Fisher's *iris* dataset. Use `Petal_Length` as the response variable and the remaining four variables as the predictors. Note that `species` is a categorical factor.\n",
    "\n",
    "Use either BIC or AIC as your criterion. Recall that in Python \"lower BIC/AIC\" equates to \"better model.\" See [here](https://stats.stackexchange.com/questions/577/is-there-any-reason-to-prefer-the-aic-or-bic-over-the-other) for some more details about the two metrics.\n",
    "\n",
    "Then perform backward feature selection using a p-value cutoff of 0.06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Zws6nLbqRG6"
   },
   "outputs": [],
   "source": [
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Species']\n",
    "iris = pd.read_csv(csv_url, names=col_names)\n",
    "\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IazZj-7b9_7M"
   },
   "source": [
    "## Check your understanding\n",
    "\n",
    "Consider the two models you built. Which of them would you choose? Convince me using at least 2 pieces of evidence.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWGLLAK/rvq+9R1A+gWaL6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
